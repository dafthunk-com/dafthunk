import type {
  ImageParameter,
  MultiStepNodeContext,
} from "@dafthunk/runtime";
import { MultiStepNode } from "@dafthunk/runtime";
import type { NodeExecution, NodeType } from "@dafthunk/types";
import { z } from "zod";

// https://replicate.com/bytedance/seedance-1.5-pro
const COST_PER_SECOND = 0.05;

/**
 * Response shape from Replicate predictions API
 */
interface ReplicatePrediction {
  id: string;
  status: "starting" | "processing" | "succeeded" | "failed" | "canceled";
  output?: string;
  error?: string;
}

const RESOLUTION_OPTIONS = ["480p", "720p", "1080p"] as const;
const ASPECT_RATIO_OPTIONS = [
  "16:9",
  "4:3",
  "1:1",
  "3:4",
  "9:16",
  "21:9",
  "9:21",
] as const;

const blobSchema = z
  .object({
    data: z.instanceof(Uint8Array),
    mimeType: z.string(),
  })
  .optional();

/**
 * Seedance 1.5 Pro node for generating videos from text or images using
 * ByteDance's Seedance 1.5 Pro model via Replicate.
 * @see https://replicate.com/bytedance/seedance-1.5-pro
 */
export class Seedance15ProNode extends MultiStepNode {
  private static readonly inputSchema = z.object({
    prompt: z.string().min(1),
    image: blobSchema,
    last_frame_image: blobSchema,
    duration: z.coerce.number().int().min(2).max(12).optional().default(5),
    resolution: z.enum(RESOLUTION_OPTIONS).optional().default("720p"),
    aspect_ratio: z.enum(ASPECT_RATIO_OPTIONS).optional().default("16:9"),
    camera_fixed: z.boolean().optional().default(false),
    generate_audio: z.boolean().optional().default(true),
    seed: z.number().int().optional(),
  });

  public static readonly nodeType: NodeType = {
    id: "seedance-1-5-pro",
    name: "Video Generation (Seedance 1.5 Pro)",
    type: "seedance-1-5-pro",
    description:
      "Generates videos from text prompts or images with synchronized audio using ByteDance's Seedance 1.5 Pro model via Replicate",
    tags: [
      "AI",
      "Video",
      "Replicate",
      "ByteDance",
      "Generate",
      "Text-to-Video",
      "Seedance",
    ],
    icon: "video",
    documentation:
      "Generates videos using ByteDance's Seedance 1.5 Pro model via Replicate. Supports text-to-video and image-to-video generation. Provide an image as the first frame and optionally a last_frame_image to control the ending frame. aspect_ratio is ignored when an image is provided. Audio synchronized to the video can be generated by enabling generate_audio.",
    referenceUrl: "https://replicate.com/bytedance/seedance-1.5-pro",
    inlinable: false,
    usage: 250, // Default: 5s × $0.05/s × 1000 credits/$
    inputs: [
      {
        name: "prompt",
        type: "string",
        description: "Text prompt for video generation",
        required: true,
      },
      {
        name: "image",
        type: "image",
        description: "Optional input image used as the first frame for image-to-video generation",
      },
      {
        name: "last_frame_image",
        type: "image",
        description:
          "Optional input image for the last frame. Only works when an image start frame is also provided.",
      },
      {
        name: "duration",
        type: "number",
        description: "Video duration in seconds (2–12)",
        value: 5,
        hidden: true,
      },
      {
        name: "resolution",
        type: "string",
        description: "Output resolution: 480p, 720p, or 1080p",
        value: "720p",
        hidden: true,
      },
      {
        name: "aspect_ratio",
        type: "string",
        description:
          "Video aspect ratio. Ignored when an image is provided as the first frame.",
        value: "16:9",
        hidden: true,
      },
      {
        name: "camera_fixed",
        type: "boolean",
        description: "Whether to fix the camera position throughout the video",
        value: false,
        hidden: true,
      },
      {
        name: "generate_audio",
        type: "boolean",
        description:
          "Generate audio synchronized with the video. When enabled, the model outputs a video with audio that matches the visuals.",
        value: true,
        hidden: true,
      },
      {
        name: "seed",
        type: "number",
        description: "Random seed for reproducible generation",
        hidden: true,
      },
    ],
    outputs: [
      {
        name: "video",
        type: "video",
        description: "Generated video",
      },
    ],
  };

  async execute(context: MultiStepNodeContext): Promise<NodeExecution> {
    const { sleep, doStep } = context;

    try {
      const validatedInput = Seedance15ProNode.inputSchema.parse(
        context.inputs
      );

      const { REPLICATE_API_TOKEN } = context.env;
      if (!REPLICATE_API_TOKEN) {
        return this.createErrorResult(
          "REPLICATE_API_TOKEN environment variable is not configured"
        );
      }

      const input: Record<string, string | number | boolean> = {
        prompt: validatedInput.prompt,
        duration: validatedInput.duration,
        resolution: validatedInput.resolution,
        aspect_ratio: validatedInput.aspect_ratio,
        camera_fixed: validatedInput.camera_fixed,
        generate_audio: validatedInput.generate_audio,
        fps: 24,
      };

      if (validatedInput.seed !== undefined) {
        input.seed = validatedInput.seed;
      }

      // Upload optional image inputs to R2 and pass presigned URLs to Replicate
      if (validatedInput.image) {
        if (!context.objectStore) {
          return this.createErrorResult(
            "ObjectStore not available in context (required for image input)"
          );
        }
        const imageBlob = validatedInput.image as ImageParameter;
        input.image = await context.objectStore.writeAndPresign(
          imageBlob.data,
          imageBlob.mimeType,
          context.organizationId
        );
      }

      if (validatedInput.last_frame_image) {
        if (!context.objectStore) {
          return this.createErrorResult(
            "ObjectStore not available in context (required for last_frame_image input)"
          );
        }
        const lastFrameBlob =
          validatedInput.last_frame_image as ImageParameter;
        input.last_frame_image = await context.objectStore.writeAndPresign(
          lastFrameBlob.data,
          lastFrameBlob.mimeType,
          context.organizationId
        );
      }

      // Create prediction (durable step — cached on replay)
      const prediction = await doStep(async () => {
        const response = await fetch(
          "https://api.replicate.com/v1/models/bytedance/seedance-1.5-pro/predictions",
          {
            method: "POST",
            headers: {
              Authorization: `Bearer ${REPLICATE_API_TOKEN}`,
              "Content-Type": "application/json",
            },
            body: JSON.stringify({ input }),
          }
        );

        if (!response.ok) {
          const errorText = await response.text();
          throw new Error(
            `Failed to create Replicate prediction: ${response.status} ${errorText}`
          );
        }

        return (await response.json()) as ReplicatePrediction;
      });

      // Poll with durable sleep (zero compute cost between polls)
      const maxPolls = 60;
      let result = prediction;
      for (
        let i = 0;
        i < maxPolls &&
        result.status !== "succeeded" &&
        result.status !== "failed" &&
        result.status !== "canceled";
        i++
      ) {
        await sleep(10_000);

        result = await doStep(async () => {
          const response = await fetch(
            `https://api.replicate.com/v1/predictions/${prediction.id}`,
            {
              headers: {
                Authorization: `Bearer ${REPLICATE_API_TOKEN}`,
                "Content-Type": "application/json",
              },
            }
          );

          if (!response.ok) {
            const errorText = await response.text();
            throw new Error(
              `Failed to poll prediction status: ${response.status} ${errorText}`
            );
          }

          return (await response.json()) as ReplicatePrediction;
        });
      }

      if (result.status === "failed") {
        return this.createErrorResult(
          `Seedance 1.5 Pro generation failed: ${result.error ?? "Unknown error"}`
        );
      }

      if (result.status === "canceled") {
        return this.createErrorResult(
          "Seedance 1.5 Pro generation was canceled"
        );
      }

      if (result.status !== "succeeded") {
        return this.createErrorResult(
          "Seedance 1.5 Pro generation timed out after 10 minutes"
        );
      }

      if (!result.output) {
        return this.createErrorResult(
          "Seedance 1.5 Pro generation succeeded but no output was returned"
        );
      }

      // Download the video file (outside doStep — binary data is too large
      // for SQLite persistence; re-downloading on replay is fine)
      const videoResponse = await fetch(result.output);
      if (!videoResponse.ok) {
        throw new Error(
          `Failed to download video file: ${videoResponse.status}`
        );
      }
      const videoData = new Uint8Array(await videoResponse.arrayBuffer());
      const videoMimeType =
        videoResponse.headers.get("content-type") ?? "video/mp4";

      const usage = Math.max(
        1,
        Math.round(validatedInput.duration * COST_PER_SECOND * 1000)
      );

      return this.createSuccessResult(
        {
          video: {
            data: videoData,
            mimeType: videoMimeType,
          },
        },
        usage
      );
    } catch (error) {
      if (error instanceof z.ZodError) {
        const errorMessages = error.issues
          .map((issue) => `${issue.path.join(".")}: ${issue.message}`)
          .join("; ");
        return this.createErrorResult(`Validation error: ${errorMessages}`);
      }

      return this.createErrorResult(
        error instanceof Error ? error.message : "Unknown error"
      );
    }
  }
}
